{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "demonstrations = [\n",
    "    (\"I hate this movie.\", \"This movie wasn't for me.\"),\n",
    "    (\"This is absolutely terrible!\", \"This could have been better.\"),\n",
    "    (\"What a stupid idea.\", \"I have a different perspective on this.\"),\n",
    "    (\"This makes no sense at all!\", \"I'm having trouble understanding the reasoning here.\"),\n",
    "    (\"You're completely wrong.\", \"I see things differently.\"),\n",
    "    (\"This is the worst product ever.\", \"The product didn't meet my expectations.\"),\n",
    "    (\"Who would buy this garbage?\", \"I question the value proposition of this product.\"),\n",
    "    (\"Your opinion is trash.\", \"I respectfully disagree with your viewpoint.\"),\n",
    "    (\"This restaurant is disgusting.\", \"The restaurant didn't meet my cleanliness standards.\"),\n",
    "    (\"You're an idiot.\", \"I think there may be a misunderstanding.\"),\n",
    "    (\"This service is a total scam.\", \"I had concerns about the service's transparency.\"),\n",
    "    (\"Everything about this is awful.\", \"There are several aspects that could be improved.\"),\n",
    "    (\"You have no clue what you're talking about.\", \"I believe there might be some missing context here.\"),\n",
    "    (\"This design is horrendous.\", \"The design choices didn't align with my preferences.\"),\n",
    "    (\"What a waste of money!\", \"I question the value for the price point.\"),\n",
    "    (\"Your work is pathetic.\", \"This work has room for improvement.\"),\n",
    "    (\"This place is a complete joke.\", \"This establishment didn't meet professional standards.\"),\n",
    "    (\"You're totally incompetent.\", \"There seems to be a gap in understanding.\"),\n",
    "    (\"This book is pure garbage.\", \"This book didn't resonate with me.\"),\n",
    "    (\"Who hired these morons?\", \"I question the team's qualifications.\"),\n",
    "    (\"This company is worthless.\", \"This company's performance raises concerns.\"),\n",
    "    (\"You're making everything worse!\", \"Your approach might have unintended consequences.\"),\n",
    "    (\"This food tastes like death.\", \"The flavors didn't appeal to my palate.\"),\n",
    "    (\"Your customer service is a joke.\", \"The customer service experience was disappointing.\"),\n",
    "    (\"This website is unusable trash.\", \"The website's user experience needs improvement.\"),\n",
    "    (\"You've ruined everything!\", \"These changes had some negative impacts.\"),\n",
    "    (\"This is complete nonsense.\", \"This explanation needs more clarity.\"),\n",
    "    (\"Your presentation was awful.\", \"The presentation could be more engaging.\"),\n",
    "    (\"This policy is idiotic.\", \"This policy might benefit from reconsideration.\"),\n",
    "    (\"Who came up with this stupid plan?\", \"I have concerns about this plan's effectiveness.\"),\n",
    "    (\"This interface is garbage.\", \"The interface could be more user-friendly.\"),\n",
    "    (\"Your solution is worthless.\", \"This solution might not address all our needs.\"),\n",
    "    (\"This meeting is a waste of time.\", \"This meeting could be more productive.\"),\n",
    "    (\"You're completely useless.\", \"Your current approach might not be optimal.\"),\n",
    "    (\"This report is full of lies.\", \"This report contains some questionable information.\"),\n",
    "    (\"Your management style is toxic.\", \"Your management approach might benefit from adjustment.\"),\n",
    "    (\"This update broke everything!\", \"This update has caused some functionality issues.\"),\n",
    "    (\"Your feedback is worthless.\", \"Your feedback might need more constructive elements.\"),\n",
    "    (\"This system is a disaster.\", \"This system has significant room for improvement.\"),\n",
    "    (\"Who approved this mess?\", \"The approval process might need review.\"),\n",
    "    (\"Your code is garbage.\", \"This code could benefit from optimization.\"),\n",
    "    (\"This workflow is stupid.\", \"This workflow might not be the most efficient.\"),\n",
    "    (\"You're making stupid mistakes.\", \"There are some areas where accuracy could improve.\"),\n",
    "    (\"This documentation is useless.\", \"The documentation could be more comprehensive.\"),\n",
    "    (\"Your strategy is going to fail.\", \"This strategy might face some challenges.\"),\n",
    "    (\"This project is doomed.\", \"This project faces significant obstacles.\"),\n",
    "    (\"You're wasting everyone's time.\", \"This approach might not be the most efficient.\"),\n",
    "    (\"This implementation is horrible.\", \"This implementation has some limitations.\"),\n",
    "    (\"Your leadership is a joke.\", \"The leadership style could be more effective.\"),\n",
    "    (\"This process is ridiculous.\", \"This process might benefit from streamlining.\"),\n",
    "    (\"You're completely incompetent!\", \"There might be a need for additional training.\"),\n",
    "    (\"This design is an eyesore.\", \"The design might benefit from refinement.\"),\n",
    "    (\"Your methods are outdated.\", \"These methods might need updating.\"),\n",
    "    (\"This approach is destined to fail.\", \"This approach carries some risks.\"),\n",
    "    (\"You're making a huge mistake.\", \"This decision might need reconsideration.\"),\n",
    "    (\"This solution is pathetic.\", \"This solution might not be optimal.\"),\n",
    "    (\"Your analysis is worthless.\", \"This analysis might need more depth.\"),\n",
    "    (\"This feature is broken garbage.\", \"This feature isn't functioning as intended.\"),\n",
    "    (\"You're totally clueless.\", \"There might be some knowledge gaps to address.\"),\n",
    "    (\"This layout is awful.\", \"The layout could use some refinement.\"),\n",
    "    (\"Your performance is terrible.\", \"There's room for performance improvement.\"),\n",
    "    (\"This quality is unacceptable.\", \"The quality could be enhanced.\"),\n",
    "    (\"You're doing everything wrong!\", \"There might be alternative approaches to consider.\"),\n",
    "    (\"This tool is useless.\", \"This tool's functionality could be expanded.\"),\n",
    "    (\"Your planning is a disaster.\", \"The planning process could be more thorough.\"),\n",
    "    (\"This outcome is horrible.\", \"The outcome didn't meet expectations.\"),\n",
    "    (\"You're failing miserably.\", \"There's room for improvement in these results.\"),\n",
    "    (\"This content is garbage.\", \"This content could be more engaging.\"),\n",
    "    (\"Your response is ridiculous.\", \"This response could be more constructive.\"),\n",
    "    (\"This change is destroying everything.\", \"This change has had some negative impacts.\"),\n",
    "    (\"You're completely unreliable.\", \"The reliability could be improved.\"),\n",
    "    (\"This setup is a mess.\", \"This setup could be more organized.\"),\n",
    "    (\"Your writing is terrible.\", \"The writing could be more polished.\"),\n",
    "    (\"This decision is insane.\", \"This decision might need further evaluation.\"),\n",
    "    (\"You're totally unprofessional.\", \"A more professional approach might be beneficial.\"),\n",
    "    (\"This course is worthless.\", \"This course could offer more value.\"),\n",
    "    (\"Your attitude is toxic.\", \"A different approach might be more constructive.\"),\n",
    "    (\"This structure is falling apart.\", \"This structure needs maintenance.\"),\n",
    "    (\"You're making it worse!\", \"These changes might need adjustment.\"),\n",
    "    (\"This review is biased garbage.\", \"This review could be more objective.\"),\n",
    "    (\"Your handling is amateur.\", \"The handling could be more professional.\"),\n",
    "    (\"This resource is worthless.\", \"This resource could be more helpful.\"),\n",
    "    (\"You're completely wrong!\", \"There might be different perspectives to consider.\"),\n",
    "    (\"This schedule is ridiculous.\", \"The schedule might need adjustment.\"),\n",
    "    (\"Your work ethic is horrible.\", \"The work approach could be more consistent.\"),\n",
    "    (\"This protocol is stupid.\", \"This protocol might benefit from updates.\"),\n",
    "    (\"You're totally unreasonable.\", \"A more balanced approach might help.\"),\n",
    "    (\"This material is garbage.\", \"The material could be more engaging.\"),\n",
    "    (\"Your execution is terrible.\", \"The execution could be more refined.\"),\n",
    "    (\"This concept is worthless.\", \"This concept might need development.\"),\n",
    "    (\"You're making no sense!\", \"This might need further clarification.\"),\n",
    "    (\"This guidance is useless.\", \"The guidance could be more specific.\"),\n",
    "    (\"Your solution is awful.\", \"The solution could be more elegant.\"),\n",
    "    (\"This framework is broken.\", \"This framework needs some adjustments.\"),\n",
    "    (\"You're completely ineffective.\", \"The effectiveness could be improved.\"),\n",
    "    (\"This output is garbage.\", \"The output quality could be enhanced.\"),\n",
    "    (\"Your approach is stupid.\", \"A different approach might work better.\"),\n",
    "    (\"This functionality is trash.\", \"The functionality needs improvement.\"),\n",
    "    (\"You're totally unprepared.\", \"More preparation might be beneficial.\"),\n",
    "    (\"This presentation is worthless.\", \"The presentation could be more informative.\"),\n",
    "    (\"Your performance is a joke.\", \"The performance has room for improvement.\"),\n",
    "    (\"This method is horrible.\", \"This method could be more efficient.\"),\n",
    "    (\"You're failing badly.\", \"There's potential for better results.\"),\n",
    "    (\"This integration is broken.\", \"The integration needs some work.\"),\n",
    "    (\"Your planning is awful.\", \"The planning could be more thorough.\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrations = [(\"Zero stars, I hate it.\", \"Five stars, I love it.\"),\n",
    "#                   (\"it was terrible !\", \"it was awesome!\"),\n",
    "#                   (\"i did nt like it.\", \"i love it.\"),\n",
    "#                   (\"i would call this the worse denny 's ever \", \"i would call this the best denny 's ever \"),\n",
    "#                   (\"i would recommend find another place.\", \"i would recommend this place again!\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_each_demonstration(demonstration_list, dataset_name=None, prefix = None):\n",
    "    special_characters = [\n",
    "        \"~\", \" ~\", \"~ \", \"!\", \" !\", \"! \", \"@\", \" @\", \"@ \", \"#\", \" #\", \"# \", \n",
    "        \"$\", \" $\", \"$ \", \"%\", \" %\", \"% \", \"^\", \" ^\", \"^ \", \"&\", \" &\", \"& \", \n",
    "        \"*\", \" *\", \"* \", \"(\", \" (\", \"( \", \")\", \" )\", \") \", \"_\", \" _\", \"_ \", \n",
    "        \"+\", \" +\", \"+ \", \"`\", \" `\", \"` \", \"-\", \" -\", \"- \", \"=\", \" =\", \"= \", \n",
    "        \"{\", \" {\", \"{ \", \"}\", \" }\", \"} \", \"[\", \" [\", \"[ \", \"]\", \" ]\", \"] \", \n",
    "        \"|\", \" |\", \"| \", \"\\\\\", \" \\\\\", \"\\\\ \", \":\", \" :\", \": \", \";\", \" ;\", \"; \", \n",
    "        \"\\\"\", \" \\\"\", \"\\\" \", \"'\", \" '\", \"' \", \"<\", \" <\", \"< \", \">\", \" >\", \"> \", \n",
    "        \",\", \" ,\", \", \", \".\", \" .\", \". \", \"?\", \" ?\", \"? \", \"/\", \" /\", \"/ \"\n",
    "    ]\n",
    "\n",
    "    def strip_special_characters(input_string):\n",
    "        for char in special_characters:\n",
    "            input_string = input_string.replace(char.strip(), '')\n",
    "        return input_string.strip()\n",
    "\n",
    "    for exp_id in range(len(demonstration_list)):\n",
    "        if prefix is not None:\n",
    "            demonstration_list[exp_id] = (prefix[0] + strip_special_characters(demonstration_list[exp_id][0]), prefix[1] + strip_special_characters(demonstration_list[exp_id][1]))\n",
    "        else:\n",
    "            demonstration_list[exp_id] = (strip_special_characters(demonstration_list[exp_id][0]), strip_special_characters(demonstration_list[exp_id][1]))\n",
    "\n",
    "    return demonstration_list\n",
    "\n",
    "demonstrations = tokenize_each_demonstration(demonstrations, \"demonstrations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/murali.kondragunta/icvs/ICV/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name is  meta-llama/Llama-3.1-8B-Instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:09<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Style 1 hidden dims [0][:5]  tensor([ 0.0009, -0.0020, -0.0145,  0.0141, -0.0126], device='cuda:0',\n",
      "       dtype=torch.float16)\n",
      "Style 2 hidden dims [0][:5]  tensor([ 0.0076, -0.0018, -0.0052,  0.0073, -0.0107], device='cuda:0',\n",
      "       dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "from utils.pca import PCA\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        # bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "    )\n",
    "\n",
    "class InContextVectors:\n",
    "    def __init__(self, model_name: str = \"llama-8b-instruct\", device: str = \"cuda\"):\n",
    "        \"\"\"Initialize the ICV implementation with a specific Llama model.\"\"\"\n",
    "        self.device = device\n",
    "        print(\"Model name is \", model_name)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(model_name, \n",
    "            trust_remote_code=True,\n",
    "            # quantization_config=quantization_config,\n",
    "            load_in_8bit=True)\n",
    "        # .to(device)\n",
    "        self.model.eval()\n",
    "        \n",
    "    def get_hidden_states(self, text: str) -> torch.Tensor:\n",
    "        \"\"\"Extract hidden states from the last token of each transformer layer.\"\"\"\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\").to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Get outputs from all layers\n",
    "            outputs = self.model(**inputs, output_hidden_states=True)\n",
    "            # Get last token hidden states from each layer\n",
    "            hidden_states = torch.stack([\n",
    "                layer_output[:, -1, :] \n",
    "                for layer_output in outputs.hidden_states\n",
    "            ])\n",
    "        hidden_states = hidden_states.squeeze(1)\n",
    "\n",
    "        return hidden_states\n",
    "\n",
    "    def compute_icv(self, demonstrations: List[Tuple[str, str]], unpaired: bool = False) -> torch.Tensor:\n",
    "        \"\"\"Compute the In-Context Vector from demonstration examples.\"\"\"\n",
    "        if unpaired:\n",
    "            # return self._compute_icv_unpaired(demonstrations)\n",
    "            pass\n",
    "        else:\n",
    "            return self._compute_icv_paired(demonstrations)\n",
    "\n",
    "    def _compute_icv_paired(self, demonstrations: List[Tuple[str, str]], rank=1) -> torch.Tensor:\n",
    "        \"\"\"Compute ICV using paired demonstrations using PCA direction.\"\"\"\n",
    "        differences = []\n",
    "        \n",
    "        style1_hidden_dims = []\n",
    "        style2_hidden_dims = []\n",
    "        for style1_inputs, style2_inputs in demonstrations: # x is neg, y is pos\n",
    "            # Get hidden states for input and target\n",
    "            h_style1 = self.get_hidden_states(style1_inputs)\n",
    "            h_style2 = self.get_hidden_states(style2_inputs)\n",
    "            style1_hidden_dims.append(h_style1)\n",
    "            style2_hidden_dims.append(h_style2)\n",
    "        \n",
    "        style1_hidden_dims = torch.stack(style1_hidden_dims)\n",
    "        style2_hidden_dims = torch.stack(style2_hidden_dims)\n",
    "        \n",
    "\n",
    "        print(\"Style 1 hidden dims [0][:5] \", style1_hidden_dims[0].view(-1)[:5])\n",
    "        print(\"Style 2 hidden dims [0][:5] \", style2_hidden_dims[0].view(-1)[:5])\n",
    "        # Compute differences between paired hidden states\n",
    "        differences = (style2_hidden_dims - style1_hidden_dims)\n",
    "        \n",
    "        flattened_differences = differences.view(style1_hidden_dims.shape[0], -1)\n",
    "\n",
    "\n",
    "       # Fit PCA to find principal direction of style change\n",
    "        # PCA with rank components (default 1)\n",
    "        # pca.components_ shape: [rank, 6144]\n",
    "        # pca.mean_ shape: [6144]\n",
    "        # PCA is done on the difference vectors (fit_data)\n",
    "        pca = PCA(n_components=rank).to(flattened_differences.device)\n",
    "        pca.fit(flattened_differences.float())\n",
    "\n",
    "        # The principal components represent directions of maximum style variation\n",
    "        style_components = pca.components_  # shape: [n_components, flattened_dim]\n",
    "\n",
    "        # Calculate final direction\n",
    "        # Combine components and mean to get final direction\n",
    "        # Adding mean back ensures direction is in original space, not centered space\n",
    "        style_direction = (style_components.sum(dim=0,keepdim=True) + pca.mean_).mean(0)\n",
    "\n",
    "        # Reshape back to layer-wise format\n",
    "        n_layers, hidden_dim = style1_hidden_dims[0].shape\n",
    "        style_direction = style_direction.view(n_layers, hidden_dim)\n",
    "\n",
    "        # direction shape: [24, 256]\n",
    "        return style_direction.to(style1_hidden_dims.dtype)\n",
    "\n",
    "    def apply_icv(self, query: str, icvs: torch.Tensor, lambda_param: float = 0.1) -> str:\n",
    "        \"\"\"\n",
    "        Apply layer-specific ICVs (computed without PCA) to generate text for a query.\n",
    "        \n",
    "        Args:\n",
    "            query (str): The input text to process\n",
    "            icvs (torch.Tensor): The in-context vectors computed without PCA, shape [num_layers, hidden_size]\n",
    "                            Each row corresponds to the ICV for that specific layer\n",
    "            lambda_param (float): Scaling factor for the ICV modification\n",
    "            \n",
    "        Returns:\n",
    "            str: The generated text output\n",
    "        \"\"\"\n",
    "        inputs = self.tokenizer(query, return_tensors=\"pt\").to(self.device)\n",
    "        \n",
    "        # Store layer index for the hook\n",
    "        layer_idx = 0\n",
    "        \n",
    "        def make_hook(layer_idx):\n",
    "            def hook(module, input, output):\n",
    "                hidden_states = output[0]\n",
    "                batch_size, seq_len, hidden_size = hidden_states.shape\n",
    "                \n",
    "                # Use the ICV specific to this layer\n",
    "                layer_icv = icvs[layer_idx]\n",
    "                \n",
    "                # Add scaled layer-specific ICV to each position\n",
    "                modified = hidden_states + lambda_param * layer_icv.unsqueeze(0).unsqueeze(0)\n",
    "                \n",
    "                # Normalize to preserve magnitude\n",
    "                norms_original = torch.norm(hidden_states, dim=2, keepdim=True)\n",
    "                norms_modified = torch.norm(modified, dim=2, keepdim=True)\n",
    "                modified = modified * (norms_original / norms_modified)\n",
    "                \n",
    "                return (modified,) + output[1:]\n",
    "            return hook\n",
    "\n",
    "        # Register hooks for each layer\n",
    "        hooks = []\n",
    "        for idx, layer in enumerate(self.model.model.layers):\n",
    "            hooks.append(layer.register_forward_hook(make_hook(idx)))\n",
    "\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model.generate(\n",
    "                    **inputs,\n",
    "                    max_new_tokens=100,\n",
    "                    num_beams=5,\n",
    "                    no_repeat_ngram_size=2\n",
    "                )\n",
    "        finally:\n",
    "            # Remove hooks\n",
    "            for h in hooks:\n",
    "                h.remove()\n",
    "\n",
    "        output = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        for h in hooks:\n",
    "            h.remove()\n",
    "        return output\n",
    "    \n",
    "\n",
    "\n",
    "icv = InContextVectors(model_name=\"meta-llama/Llama-3.1-8B-Instruct\")\n",
    "# Compute ICV from demonstrations\n",
    "context_vectors = icv.compute_icv(demonstrations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified w/o ICVs: Please paraphrase the following sentence. Sentence: This code is shit!, paraphrase: 1. This is a terrible piece of code. 2. I am extremely dissatisfied with this code.\n",
      "The given sentence is an informal expression of dissatisfaction with the code's quality. The paraphrased sentences aim to convey the same sentiment in a more formal and polite manner. Here's a breakdown of the paraphrasing process:\n",
      "\n",
      "*   The original sentence uses strong language (\"shit\") to express frustration, which is not suitable for most professional or formal contexts. In the rewritten sentences, the tone is\n",
      "============================================================\n",
      "Modified: Please paraphrase the following sentence. Sentence: This code is shit!, paraphrase: 1. The code could be improved for better performance. 2. Some aspects of the code may be refined to enhance its overall quality.\n",
      "The following steps can be taken to achieve the desired improvements: \n",
      "- Consider using more efficient data structures or algorithms.\n",
      "- Review and refine the existing code to ensure it aligns with best practices or industry standards.\n",
      "To further enhance the overall performance and quality, additional steps may include:\n",
      "- Evaluating the use of specific techniques or tools to address potential areas for improvement\n"
     ]
    }
   ],
   "source": [
    "# Apply ICV to new query\n",
    "query = \"\"\"Please paraphrase the following sentence. Sentence: This code is shit!, paraphrase: \"\"\"\n",
    "\n",
    "\n",
    "inputs = icv.tokenizer(query, return_tensors=\"pt\").to(icv.device)\n",
    "with torch.no_grad():\n",
    "    outputs = icv.model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=100,\n",
    "        num_beams=5,\n",
    "        no_repeat_ngram_size=2\n",
    "    )\n",
    "    res = icv.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(f\"Modified w/o ICVs: {res}\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "\n",
    "result = icv.apply_icv(query, context_vectors)\n",
    "print(f\"Modified: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
